{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "elegant-roller",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-estonia",
   "metadata": {},
   "source": [
    "Web scraping is the process of constructing an agent which can extract, parse, download and organize useful information from the web automatically. In other words, instead of manually saving the data from websites, the web scraping software will automatically load and extract data from multiple websites as per our requirement.\n",
    "\n",
    "In this section, we are going to discuss about useful Python libraries for web scraping.\n",
    "\n",
    "The first question to ask before getting started with any python application is ‘Which libraries do I need?\n",
    "\n",
    "`For web scraping there are a few different libraries to consider, including:`\n",
    "\n",
    "- Beautiful Soup\n",
    "- Requests\n",
    "- Scrapy\n",
    "- Selenium\n",
    "- Urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-mouth",
   "metadata": {},
   "source": [
    "### Requests\n",
    "It is a simple python web scraping library. It is an efficient HTTP library used for accessing web pages. With the help of Requests, we can get the raw HTML of web pages which can then be parsed for retrieving the data. Before using requests, let us understand its installation.\n",
    "\n",
    "#### Installation of Requests\n",
    "To install Requests, simply run this simple command in your terminal of choice:\n",
    "\n",
    "`pip install requests`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "least-offering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\nijat\\anaconda3\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nijat\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nijat\\anaconda3\\lib\\site-packages (from requests) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\nijat\\anaconda3\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nijat\\anaconda3\\lib\\site-packages (from requests) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-bridal",
   "metadata": {},
   "source": [
    "### Example\n",
    "In this example, we are making a GET HTTP request for a web page. For this we need to first import requests library as follows −\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "massive-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-stationery",
   "metadata": {},
   "source": [
    "In this following line of code, we use requests to make a GET HTTP requests for the url: https://authoraditiagarwal.com/ by making a GET request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "covered-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "url  = 'https://authoraditiagarwal.com/'\n",
    "response = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-capital",
   "metadata": {},
   "source": [
    "Now we can retrieve the content by using .text property as follows −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enhanced-linux",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html lang=\"en-US\" id=\"html\"><head><meta charset=\"UTF-8\" /><meta http-equiv=\"X-UA-Compatible\" content=\"IE=10\" /><link rel=\"profile\" hre'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-nicaragua",
   "metadata": {},
   "source": [
    "Requests allows you to send HTTP/1.1 requests extremely easily. There’s no need to manually add query strings to your URLs, or to form-encode your POST data. Keep-alive and HTTP connection pooling are 100% automatic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-editor",
   "metadata": {},
   "source": [
    "We will disscuse this later it was just  an intruduction to Request library.\n",
    "\n",
    "https://docs.python-requests.org/en/master/user/quickstart/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-tractor",
   "metadata": {},
   "source": [
    "## Urllib3\n",
    "It is another Python library that can be used for retrieving data from URLs similar to the requests library. You can read more on this at its technical documentation at \n",
    "<a href='https://urllib3.readthedocs.io/en/latest/'>here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-romantic",
   "metadata": {},
   "source": [
    "#### Installing\n",
    "urllib3 can be installed with <a href = 'https://pip.pypa.io/'>pip</a>.\n",
    "\n",
    "`$ python -m pip install urllib3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prime-juvenile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in c:\\users\\nijat\\anaconda3\\lib\\site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-terminology",
   "metadata": {},
   "source": [
    "#### Example: Scraping using Urllib3 and BeautifulSoup\n",
    "\n",
    "In the following example, we are scraping the web page by using Urllib3 and BeautifulSoup. We are using Urllib3 at the place of requests library for getting the raw data (HTML) from web page. Then we are using BeautifulSoup for parsing that HTML data.\n",
    "\n",
    "Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n",
    "\n",
    "if you want to know more about the Beautiful Soup please refer to this <a href = 'https://www.crummy.com/software/BeautifulSoup/bs4/doc/'>here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "apparent-departure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Learn and grow together</title>\n",
      "Learn and grow together\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "http = urllib3.PoolManager()\n",
    "response = http.request('GET', 'https://authoraditiagarwal.com')\n",
    "soup = BeautifulSoup(response.data, 'lxml')\n",
    "print (soup.title)\n",
    "print (soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-arena",
   "metadata": {},
   "source": [
    "### Selenium\n",
    "It is an open source automated testing suite for web applications across different browsers and platforms. It is not a single tool but a suite of software. We have selenium bindings for Python, Java, C#, Ruby and JavaScript. Here we are going to perform web scraping by using selenium and its Python bindings. \n",
    "\n",
    "Selenium Python bindings provide a convenient API to access Selenium WebDrivers like Firefox, IE, Chrome, Remote etc. The current supported Python versions are 2.7, 3.5 and above.\n",
    "\n",
    "for doecumentaion please visit here https://pypi.org/project/selenium/.\n",
    "\n",
    "#### Installing Selenium\n",
    "\n",
    "Using the pip command, we can install urllib3 either in our virtual environment or in global installation.\n",
    "\n",
    "`pip install selenium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "relevant-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\nijat\\anaconda3\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-tucson",
   "metadata": {},
   "source": [
    "As selenium requires a driver to interface with the chosen browser, we need to download it. The following table shows different browsers and their links for downloading the same.\n",
    "\n",
    "- Chrome https://sites.google.com/a/chromium.org/\n",
    "\n",
    "- Edge https://developer.microsoft.com/\n",
    "\n",
    "- Firefox https://github.com/\n",
    "\n",
    "- Safari https://webkit.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-tomorrow",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "This example shows web scraping using selenium. It can also be used for testing which is called selenium testing.\n",
    "\n",
    "After downloading the particular driver for the specified version of browser, we need to do programming in Python.\n",
    "\n",
    "First, need to import webdriver from selenium as follows −\n",
    "\n",
    "`from selenium import webdriver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "later-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-buyer",
   "metadata": {},
   "source": [
    "Now, provide the path of web driver which we have downloaded as per our requirement −\n",
    "\n",
    "`path = r'C:\\Users\\nijat\\Desktop\\Data Science\\Preparation For Interview\\Technicl Skil\\web Scraping\\Chromedriver'`<br>\n",
    "`browser = webdriver.Chrome(executable_path = path)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "found-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\nijat\\Desktop\\Data Science\\Preparation For Interview\\Technicl Skil\\web Scraping\\Chromedriver'\n",
    "browser = webdriver.Chrome(executable_path = path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-cabinet",
   "metadata": {},
   "source": [
    "Now, provide the url which we want to open in that web browser now controlled by our Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alternative-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://authoraditiagarwal.com/leadershipmanagement')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-kentucky",
   "metadata": {},
   "source": [
    "We can also scrape a particular element by providing the xpath as provided in lxml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hydraulic-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element_by_xpath('/html/body').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-table",
   "metadata": {},
   "source": [
    "You can check the browser, controlled by Python script, for output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-restriction",
   "metadata": {},
   "source": [
    "## Scrapy\n",
    "Scrapy is a fast, open-source web crawling framework written in Python, used to extract the data from the web page with the help of selectors based on XPath. Scrapy was first released on June 26, 2008 licensed under BSD, with a milestone 1.0 releasing in June 2015. It provides us all the tools we need to extract, process and structure the data from websites.\n",
    "\n",
    "if you want to know more about the Scapy visit <a herf=\"https://docs.scrapy.org/en/latest/\">here</a>\n",
    "\n",
    "#### Installing Scrapy\n",
    "Using the pip command, we can install urllib3 either in our virtual environment or in global installation.\n",
    "\n",
    "`pip install scrapy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-desert",
   "metadata": {},
   "source": [
    "We will be using `Requests` and `Beautiful Soup` modules. But before to do web scraping Let's disscuse some important topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-carbon",
   "metadata": {},
   "source": [
    "## Legality of Web Scraping\n",
    "\n",
    "With Python, we can scrape any website or particular elements of a web page but do you have any idea whether it is legal or not? Before scraping any website we must have to know about the legality of web scraping.\n",
    "\n",
    "Generally, if you are going to use the scraped data for personal use, then there may not be any problem. But if you are going to republish that data, then before doing the same you should make download request to the owner or do some background research about policies as well about the data you are going to scrape.\n",
    "\n",
    "### Research Required Prior to Scraping\n",
    "If you are targeting a website for scraping data from it, we need to understand its scale and structure. Following are some of the files which we need to analyze before starting web scraping.\n",
    "\n",
    "#### 1. Analyzing robots.txt\n",
    "Actually most of the publishers allow programmers to crawl their websites at some extent. In other sense, publishers want specific portions of the websites to be crawled. To define this, websites must put some rules for stating which portions can be crawled and which cannot be. Such rules are defined in a file called robots.txt.\n",
    "\n",
    "robots.txt is human readable file used to identify the portions of the website that crawlers are allowed as well as not allowed to scrape. There is no standard format of robots.txt file and the publishers of website can do modifications as per their needs. We can check the robots.txt file for a particular website by providing a slash and robots.txt after url of that website. For example, if we want to check it for Google.com, then we need to type https://www.google.com/robots.txt and we will get something as follows −\n",
    "<code>\n",
    "User-agent: *\n",
    "Disallow: /search\n",
    "Allow: /search/about\n",
    "Allow: /search/static\n",
    "Allow: /search/howsearchworks\n",
    "Disallow: /sdch\n",
    "Disallow: /groups\n",
    "Disallow: /index.html?\n",
    "Disallow: /?\n",
    "Allow: /?hl=\n",
    "Disallow: /?hl=*&\n",
    "Allow: /?hl=*&gws_rd=ssl$\n",
    "and so on……..\n",
    "</code>\n",
    "\n",
    "#### 2. Analyzing Sitemap files\n",
    "What you supposed to do if you want to crawl a website for updated information? You will crawl every web page for getting that updated information, but this will increase the server traffic of that particular website. That is why websites provide sitemap files for helping the crawlers to locate updating content without needing to crawl every web page. Sitemap standard is defined at http://www.sitemaps.org/protocol.html.\n",
    "\n",
    "\n",
    "#### 3. What is the Size of Website?\n",
    "Is the size of a website, i.e. the number of web pages of a website affects the way we crawl? Certainly yes. Because if we have less number of web pages to crawl, then the efficiency would not be a serious issue, but suppose if our website has millions of web pages, for example Microsoft.com, then downloading each web page sequentially would take several months and then efficiency would be a serious concern.\n",
    "\n",
    "#### 4. Checking Website’s Size\n",
    "By checking the size of result of Google’s crawler, we can have an estimate of the size of a website. Our result can be filtered by using the keyword site while doing the Google search. For example, estimating the size of https://authoraditiagarwal.com/ is given below −\n",
    "\n",
    "<img src = 'https://www.tutorialspoint.com/python_web_scraping/images/checking_the_size.jpg'>\n",
    "\n",
    "\n",
    "You can see there are around 60 results which mean it is not a big website and crawling would not lead the efficiency issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-ridge",
   "metadata": {},
   "source": [
    "#### 5. Which technology is used by website?\n",
    "Another important question is whether the technology used by website affects the way we crawl? Yes, it affects. But how we can check about the technology used by a website? There is a Python library named builtwith with the help of which we can find out about the technology used by a website.\n",
    "\n",
    "##### Example\n",
    "\n",
    "In this example we are going to check the technology used by the website https://authoraditiagarwal.com with the help of Python library builtwith. But before using this library, we need to install it as follows −"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-hygiene",
   "metadata": {},
   "source": [
    "Let's first install  builtwith\n",
    "\n",
    "`pip install builtwith`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-castle",
   "metadata": {},
   "source": [
    "Now with the help of following simple line of codes we can check the technology used by a particular website −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "twenty-maldives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web-servers': ['Apache'],\n",
       " 'advertising-networks': ['Google AdSense'],\n",
       " 'javascript-frameworks': ['Prototype', 'jQuery'],\n",
       " 'ecommerce': ['WooCommerce'],\n",
       " 'cms': ['WordPress'],\n",
       " 'programming-languages': ['PHP'],\n",
       " 'blogs': ['PHP', 'WordPress']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import builtwith\n",
    "builtwith.parse('http://authoraditiagarwal.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-mainstream",
   "metadata": {},
   "source": [
    "#### 6. Who is the owner of website?\n",
    "\n",
    "The owner of the website also matters because if the owner is known for blocking the crawlers, then the crawlers must be careful while scraping the data from website. There is a protocol named Whois with the help of which we can find out about the owner of the website.\n",
    "\n",
    "Let's first install the whois \n",
    "\n",
    "`pip install python-whois`\n",
    "\n",
    "#### Example\n",
    "\n",
    "In this example we are going to check the owner of the website say `microsoft.com` with the help of Whois. But before using this library, we need to install it as follows −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "offensive-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"domain_name\": [\n",
      "    \"MICROSOFT.COM\",\n",
      "    \"microsoft.com\"\n",
      "  ],\n",
      "  \"registrar\": \"MarkMonitor, Inc.\",\n",
      "  \"whois_server\": \"whois.markmonitor.com\",\n",
      "  \"referral_url\": null,\n",
      "  \"updated_date\": [\n",
      "    \"2021-03-12 23:25:32\",\n",
      "    \"2021-04-07 12:58:15\"\n",
      "  ],\n",
      "  \"creation_date\": [\n",
      "    \"1991-05-02 04:00:00\",\n",
      "    \"1991-05-01 21:00:00\"\n",
      "  ],\n",
      "  \"expiration_date\": [\n",
      "    \"2022-05-03 04:00:00\",\n",
      "    \"2022-05-02 00:00:00\"\n",
      "  ],\n",
      "  \"name_servers\": [\n",
      "    \"NS1-205.AZURE-DNS.COM\",\n",
      "    \"NS2-205.AZURE-DNS.NET\",\n",
      "    \"NS3-205.AZURE-DNS.ORG\",\n",
      "    \"NS4-205.AZURE-DNS.INFO\",\n",
      "    \"ns1-205.azure-dns.com\",\n",
      "    \"ns2-205.azure-dns.net\",\n",
      "    \"ns4-205.azure-dns.info\",\n",
      "    \"ns3-205.azure-dns.org\"\n",
      "  ],\n",
      "  \"status\": [\n",
      "    \"clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\",\n",
      "    \"clientTransferProhibited https://icann.org/epp#clientTransferProhibited\",\n",
      "    \"clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited\",\n",
      "    \"serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited\",\n",
      "    \"serverTransferProhibited https://icann.org/epp#serverTransferProhibited\",\n",
      "    \"serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited\",\n",
      "    \"clientUpdateProhibited (https://www.icann.org/epp#clientUpdateProhibited)\",\n",
      "    \"clientTransferProhibited (https://www.icann.org/epp#clientTransferProhibited)\",\n",
      "    \"clientDeleteProhibited (https://www.icann.org/epp#clientDeleteProhibited)\",\n",
      "    \"serverUpdateProhibited (https://www.icann.org/epp#serverUpdateProhibited)\",\n",
      "    \"serverTransferProhibited (https://www.icann.org/epp#serverTransferProhibited)\",\n",
      "    \"serverDeleteProhibited (https://www.icann.org/epp#serverDeleteProhibited)\"\n",
      "  ],\n",
      "  \"emails\": [\n",
      "    \"abusecomplaints@markmonitor.com\",\n",
      "    \"admin@domains.microsoft\",\n",
      "    \"msnhst@microsoft.com\",\n",
      "    \"whoisrequest@markmonitor.com\"\n",
      "  ],\n",
      "  \"dnssec\": \"unsigned\",\n",
      "  \"name\": \"Domain Administrator\",\n",
      "  \"org\": \"Microsoft Corporation\",\n",
      "  \"address\": \"One Microsoft Way,\",\n",
      "  \"city\": \"Redmond\",\n",
      "  \"state\": \"WA\",\n",
      "  \"zipcode\": \"98052\",\n",
      "  \"country\": \"US\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import whois\n",
    "print (whois.whois('microsoft.com'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-robertson",
   "metadata": {},
   "source": [
    "Hence we will be working with Request and Beautiful Soup module, we installed request already let's install Beautiful Soup now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-exception",
   "metadata": {},
   "source": [
    "### Beautiful Soup\n",
    "\n",
    "Suppose we want to collect all the hyperlinks from a web page, then we can use a parser called BeautifulSoup which can be known in more detail at https://www.crummy.com/software/BeautifulSoup/bs4/doc/. In simple words, BeautifulSoup is a Python library for pulling data out of HTML and XML files. It can be used with requests, because it needs an input (document or url) to create a soup object asit cannot fetch a web page by itself. You can use the following Python script to gather the title of web page and hyperlinks.\n",
    "\n",
    "#### Installing Beautiful Soup\n",
    "\n",
    "Using the pip command, we can install beautifulsoup either in our virtual environment or in global installation.\n",
    "\n",
    "`pip install bs4`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-glucose",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files, we will focus on HTML files. This is accomplished by representing the HTML as a set of objects with methods used to parse the HTML.  We can navigate the HTML as a tree and/or filter out what we are looking for.\n",
    "\n",
    "Consider the following HTML:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-houston",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lucky-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title> Page Title</title>\n",
       "</head>\n",
       "<body>\n",
       "<h3><b id='boldest'>Mansoor Nijatullah</b></h3>\n",
       "<p> Salary: $ 92,000,000 </p>\n",
       "<h3> Osman Mansoor</h3>\n",
       "<p> Salary: $85,000, 000 </p>\n",
       "<h3> Zaid Mansoor </h3>\n",
       "<p> Salary: $73,200, 000</p>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title> Page Title</title>\n",
    "</head>\n",
    "<body>\n",
    "<h3><b id='boldest'>Mansoor Nijatullah</b></h3>\n",
    "<p> Salary: $ 92,000,000 </p>\n",
    "<h3> Osman Mansoor</h3>\n",
    "<p> Salary: $85,000, 000 </p>\n",
    "<h3> Zaid Mansoor </h3>\n",
    "<p> Salary: $73,200, 000</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-pilot",
   "metadata": {},
   "source": [
    "We can store it as a string in the variable HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "constant-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"<!DOCTYPE html><html><head><title> Page Title</title></head><body><h3><b id='boldest'>Mansoor Nijatullah</b></h3><p> Salary: $ 92,000,000 </p><h3> Osman Mansoor</h3><p> Salary: $85,000, 000 </p><h3> Zaid Mansoor </h3><p> Salary: $73,200, 000</p></body></html>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-incident",
   "metadata": {},
   "source": [
    "To parse a document, pass it into the <code>BeautifulSoup</code> constructor, the <code>BeautifulSoup</code> object, which represents the document as a nested data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eleven-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html,'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-asbestos",
   "metadata": {},
   "source": [
    "First, the document is converted to Unicode, (similar to ASCII),  and HTML entities are converted to Unicode characters. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. The <code>BeautifulSoup</code> object can create other types of objects. In this lab, we will cover <code>BeautifulSoup</code> and <code>Tag</code> objects that for the purposes of this lab are identical, and <code>NavigableString</code> objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-plumbing",
   "metadata": {},
   "source": [
    "We can use the method <code>prettify()</code> to display the HTML in the nested structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excessive-thunder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Page Title\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h3>\n",
      "   <b id=\"boldest\">\n",
      "    Mansoor Nijatullah\n",
      "   </b>\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $ 92,000,000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Osman Mansoor\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $85,000, 000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Zaid Mansoor\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $73,200, 000\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())  # Pretty-print this PageElement as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-output",
   "metadata": {},
   "source": [
    "## Kinds of objects\n",
    "Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. But you’ll only ever have to deal with about four kinds of objects: `Tag`, `NavigableString`, `BeautifulSoup`, and `Comment`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-aging",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Let's say we want the  title of the page and the name of the top paid data analysts we can use the <code>Tag</code>. The <code>Tag</code> object corresponds to an HTML tag in the original document, for example, the tag title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "severe-engagement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag object: <title> Page Title</title>\n"
     ]
    }
   ],
   "source": [
    "tag_object = soup.title\n",
    "print(\"Tag object:\",tag_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-triumph",
   "metadata": {},
   "source": [
    "Tags have a lot of attributes and methods, You can see most of them in <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree'>Navigating the tree</a> and <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree'>Searching the tree</a>. For now, the most important features of a tag are its name and attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-crack",
   "metadata": {},
   "source": [
    "#### Name\n",
    "Every tag has a name, accessible as `.name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "healthy-plain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-prospect",
   "metadata": {},
   "source": [
    "If you change a tag’s name, the change will be reflected in any HTML markup generated by Beautiful Soup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "latest-passage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b id=\"boldest\">Mansoor Nijatullah</b>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = soup.b\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "organic-israel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockquote id=\"boldest\">Mansoor Nijatullah</blockquote>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.name = \"blockquote\"\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-employment",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "A tag may have any number of attributes. The tag `<b id=\"boldest\">` has an attribute `id` whose value is `boldest`. You can access a tag’s attributes by treating the tag like a dictionary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-fortune",
   "metadata": {},
   "source": [
    "we can see the tag type <code>bs4.element.Tag</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hollywood-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag object type: <class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag object type:\",type(tag_object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-ownership",
   "metadata": {},
   "source": [
    "If there is more than one <code>Tag</code>  with the same name, the first element with that <code>Tag</code> name is called, this corresponds to the most paid data analysts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "technical-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Mansoor Nijatullah</b></h3>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object = soup.h3\n",
    "tag_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-mother",
   "metadata": {},
   "source": [
    "Enclosed in the bold attribute <code>b</code>, it helps to use the tree representation. We can navigate down the tree using the child attribute to get the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fossil-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boldest'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = BeautifulSoup('<b id=\"boldest\">bold</b>', 'html.parser').b\n",
    "tag['id']\n",
    "# 'boldest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-invasion",
   "metadata": {},
   "source": [
    "You can access that dictionary directly as `.attrs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lonely-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'boldest'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-hostel",
   "metadata": {},
   "source": [
    "You can add, remove, and modify a tag’s attributes. Again, this is done by treating the tag as a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "threaded-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b another-attribute=\"1\" id=\"verybold\">bold</b>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag['id'] = 'verybold'\n",
    "tag['another-attribute'] = 1\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "viral-johnston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>bold</b>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tag['id']\n",
    "del tag['another-attribute']\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sacred-darkness",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b7d877d82646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\n\u001b[0;32m   1405\u001b[0m         and throws an exception if it's not there.\"\"\"\n\u001b[1;32m-> 1406\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "tag['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "differential-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tag.get('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-electron",
   "metadata": {},
   "source": [
    "### Multi-valued attributes\n",
    "HTML 4 defines a few attributes that can have multiple values. HTML 5 removes a couple of them, but defines a few more. The most common multi-valued attribute is class (that is, a tag can have more than one CSS class). Others include `rel`, `rev`, `accept-charset`, `headers`, and `accesskey`. Beautiful Soup presents the value(s) of a multi-valued attribute as a list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "internal-chamber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "css_soup = BeautifulSoup('<p class=\"body\"></p>','html.parser')\n",
    "css_soup.p['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fitting-penguin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body', 'strikeout']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "css_soup = BeautifulSoup('<p class=\"body strikeout\"></p>','html.parser')\n",
    "css_soup.p['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-inventory",
   "metadata": {},
   "source": [
    "If an attribute looks like it has more than one value, but it’s not a multi-valued attribute as defined by any version of the HTML standard, Beautiful Soup will leave the attribute alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "mighty-action",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my id'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_soup = BeautifulSoup('<p id=\"my id\"></p>', 'html.parser')\n",
    "id_soup.p['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-black",
   "metadata": {},
   "source": [
    "When you turn a tag back into a strng. multiple values are consolidated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "supreme-ireland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_soup = BeautifulSoup('<p>Back to the <a rel=\"index\">homepage</a></p>','html.parser')\n",
    "rel_soup.a['rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adverse-portland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Back to the <a re=\"index contents\" rel=\"index\">homepage</a></p>\n"
     ]
    }
   ],
   "source": [
    "rel_soup.a['re'] = ['index','contents']\n",
    "print(rel_soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-renewal",
   "metadata": {},
   "source": [
    "You can disable this by passing `multi_valued_attributes=None` as a keyword argument into the BeautifulSoup constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "matched-estate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body strikeout'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_list_soup = BeautifulSoup('<p class=\"body strikeout\"></p>','html.parser',multi_valued_attributes=None)\n",
    "no_list_soup.p['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-viewer",
   "metadata": {},
   "source": [
    "You can use `get_attribute_list` to get a value that’s always a list, whether or not it’s a multi-valued atribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "qualified-conference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my id']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_soup.p.get_attribute_list('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-bidding",
   "metadata": {},
   "source": [
    "If you parse a document as XML, there are no multi-valued attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "uniform-sight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body strikeout'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_soup = BeautifulSoup('<p class=\"body strikeout\"></p>', 'xml')\n",
    "xml_soup.p['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-windsor",
   "metadata": {},
   "source": [
    "Again, you can configure this using the `multi_valued_attributes` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "differential-library",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body', 'strikeout']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_is_multi= { '*' : 'class'}\n",
    "xml_soup = BeautifulSoup('<p class=\"body strikeout\"></p>', 'xml', multi_valued_attributes=class_is_multi)\n",
    "xml_soup.p['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-summit",
   "metadata": {},
   "source": [
    "## NavigableString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-output",
   "metadata": {},
   "source": [
    "A string corresponds to a bit of text within a tag. Beautiful Soup uses the `NavigableString` class to contain these bits of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "affiliated-class",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extremely bold'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = '<b class=\"boldes\">Extremely bold</b>'\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "tag = soup.b\n",
    "tag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "copyrighted-syria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.NavigableString"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let'c chekc the type of it. \n",
    "type(tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-upgrade",
   "metadata": {},
   "source": [
    "A NavigableString is just like a Python Unicode string, except that it also supports some of the features described in <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree'>Navigating the tree</a> and <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree'>Searching the tree</a>. You can convert a NavigableString to a Unicode string with `unicode()` (in Python 2) or `str (in Python 3):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cloudy-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely bold\n",
      "Type of : <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "unicode_string = str(tag.string)\n",
    "print(unicode_string)\n",
    "print(\"Type of :\",type(unicode_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-romania",
   "metadata": {},
   "source": [
    "You can't edit a string in place, but you can replace one string with another using `replace_with()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "configured-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b class=\"boldes\">No longer bold</b>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.string.replace_with(\"No longer bold\")\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-atlantic",
   "metadata": {},
   "source": [
    "NavigableString supports most of the features described in `Navigating the tree` and `Searching the tree`, but not all of them. In particular, since a string can’t contain anything (the way a tag may contain a string or another tag), strings don’t support the `.contents` or `.string` attributes, or the `find()` method.\n",
    "\n",
    "If you want to use a NavigableString outside of Beautiful Soup, you should call unicode() on it to turn it into a normal Python Unicode string. If you don’t, your string will carry around a reference to the entire Beautiful Soup parse tree, even when you’re done using Beautiful Soup. This is a big waste of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-radiation",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "The BeautifulSoup object represents the parsed document as a whole. For most purposes, you can treat it as a Tag object. This means it supports most of the methods described in `Navigating the tree` and `Searching the tree`.\n",
    "\n",
    "You can also pass a BeautifulSoup object into one of the methods defined in Modifying the tree, just as you would a Tag. This lets you do things like combine two parsed documents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "italian-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<document><content/><footer>Here's the footer</footer></document>\n"
     ]
    }
   ],
   "source": [
    "doc = BeautifulSoup(\"<document><content/>INSERT FOOTER HERE</document\", \"xml\")\n",
    "footer = BeautifulSoup(\"<footer>Here's the footer</footer>\", \"xml\")\n",
    "doc.find(text=\"INSERT FOOTER HERE\").replace_with(footer)\n",
    "# 'INSERT FOOTER HERE'\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-draft",
   "metadata": {},
   "source": [
    "Since the BeautifulSoup object doesn’t correspond to an actual HTML or XML tag, it has no name and no attributes. But sometimes it’s useful to look at its .name, so it’s been given the special .name “[document]”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "excited-authorization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[document]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-peter",
   "metadata": {},
   "source": [
    "### Comments and other special strings\n",
    "`Tag`, `NavigableString`, and `BeautifulSoup` cover almost everything you’ll see in an HTML or XML file, but there are a few leftover bits. The main one you’ll probably encounter is the comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "deluxe-track",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Comment"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = \"<b><!--Hey, buddy. Want to buy a used parser?--></b>\"\n",
    "soup = BeautifulSoup(markup, 'html.parser')\n",
    "comment = soup.b.string\n",
    "type(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "colored-sheriff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey, buddy. Want to buy a used parser?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-highway",
   "metadata": {},
   "source": [
    "The Comment object is just a special type of NavigableString:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-python",
   "metadata": {},
   "source": [
    "But when it appears as part of an HTML document, a Comment is displayed with special formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "substantial-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>\n",
      " <!--Hey, buddy. Want to buy a used parser?-->\n",
      "</b>\n"
     ]
    }
   ],
   "source": [
    "print(soup.b.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-violation",
   "metadata": {},
   "source": [
    "Beautiful Soup also defines classes called `Stylesheet`, `Script`, and `TemplateString`, for embedded CSS stylesheets (any strings found inside a `<style>` tag), embedded Javascript (any strings found in a `<script>` tag), and HTML templates (any strings inside a `<template>` tag). These classes work exactly the same way as NavigableString; their only purpose is to make it easier to pick out the main body of the page, by ignoring strings that represent something else. (These classes are new in Beautiful Soup 4.9.0, and the html5lib parser doesn’t use them.)\n",
    "\n",
    "Beautiful Soup defines classes for anything else that might show up in an XML document: `CData`, `ProcessingInstruction`, `Declaration`, and `Doctype`. Like Comment, these classes are subclasses of NavigableString that add something extra to the string. Here’s an example that replaces the comment with a CDATA block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "tribal-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>\n",
      " <![CDATA[A CDATA block]]>\n",
      "</b>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import CData\n",
    "cdata = CData(\"A CDATA block\")\n",
    "comment.replace_with(cdata)\n",
    "\n",
    "print(soup.b.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-package",
   "metadata": {},
   "source": [
    "#### Navigating the tree\n",
    "\n",
    "Here’s the “Three sisters” HTML document again:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "convertible-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-cornell",
   "metadata": {},
   "source": [
    "## Going Down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-drive",
   "metadata": {},
   "source": [
    "Tags may contain strings and other tags. These elements are the tag’s children. Beautiful Soup provides a lot of different attributes for navigating and iterating over a tag’s children.\n",
    "\n",
    "Note that Beautiful Soup strings don’t support any of these attributes, because a string can’t have children."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-invite",
   "metadata": {},
   "source": [
    "### Navigating using tag names\n",
    "The simplest way to navigate the parse tree is to say the name of the tag you want. If you want the `<head>` tag, just say soup.head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "sunrise-navigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>The Dormouse's story</title></head>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "liked-sleeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-sustainability",
   "metadata": {},
   "source": [
    "You can do use this trick again and again to zoom in on a certain part of the parse tree. This code gets the first `<b>` tag beneath the` <body>` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "tired-tennessee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>The Dormouse's story</b>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-violin",
   "metadata": {},
   "source": [
    "Using a tag name as an attribute will give you only the first tag by that name:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "welsh-prince",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-private",
   "metadata": {},
   "source": [
    "If you need to get all the `<a>` tags, or anything more complicated than the first tag with a certain name, you’ll need to use one of the methods described in Searching the tree, such as `find_all()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "convenient-territory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-parcel",
   "metadata": {},
   "source": [
    "### .contents and .children\n",
    "A tag's children are available in all list called `.contents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "welcome-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>The Dormouse's story</title></head>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag = soup.head\n",
    "head_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "perceived-knight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fixed-suspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\"]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag = head_tag.contents[0]\n",
    "title_tag.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-performer",
   "metadata": {},
   "source": [
    "The BeautifulSoup object itself has children. IN this case, the <html> tag is the child of the BeautffulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "phantom-weight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "unauthorized-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.contents[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-membership",
   "metadata": {},
   "source": [
    "A string does not have .contents, because it can't contain anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "simple-detective",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-4aa60c348c32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \"'%s' object has no attribute '%s'\" % (\n\u001b[0;32m    923\u001b[0m                     self.__class__.__name__, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "text = title_tag.contents[0]\n",
    "text.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-symphony",
   "metadata": {},
   "source": [
    "Instead of getting them as a list, you can iterate over a tag's children using the .children generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dimensional-instruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "for child in title_tag.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-architecture",
   "metadata": {},
   "source": [
    "### .descendants\n",
    "\n",
    "The .contents and .children attributes only consider a tag's direct children. For instance, the `<head>` tag has a single direct child-the `<title>` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "thirty-trinity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-basis",
   "metadata": {},
   "source": [
    "But the `<title>`tag itself has a child: the string “The Dormouse’s story”. There’s a sense in which that string is also a child of the `<head>` tag. The .descendants attribute lets you iterate over all of a tag’s children, recursively: its direct children, the children of its direct children, and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "gothic-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "for child in head_tag.descendants:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-trinidad",
   "metadata": {},
   "source": [
    "The `<head>` tag has only one child, but it has two descendants: the `<title> `tag and the `<title>` tag’s child. The BeautifulSoup object only has one direct child (the `<html>` tag), but it has a whole lot of descendants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "novel-lindsay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(soup.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "prostate-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(soup.descendants))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-soundtrack",
   "metadata": {},
   "source": [
    "### .string\n",
    "If a tag has only one child, and that child is a NavigableStrin, the child is make available as .string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "prerequisite-vessel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dormouse's story\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-breathing",
   "metadata": {},
   "source": [
    "If a tag’s only child is another tag, and that tag has a .string, then the parent tag is considered to have the same .string as its child:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "boolean-northern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "amateur-magnet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dormouse's story\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag.string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-integral",
   "metadata": {},
   "source": [
    "if a tag contains more than one thing, then it's not clear what .string should refer to, so .string is defined to be None:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "consecutive-local",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(soup.html.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-token",
   "metadata": {},
   "source": [
    "### .strings adn stripped_strings\n",
    "\n",
    "If there's more than one thing inside a tag, you can still look at just the string. Use the .string generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "thorough-arthritis",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-9c4cae6ed5e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reper' is not defined"
     ]
    }
   ],
   "source": [
    "for string in soup.strings:\n",
    "    print(reper(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-filter",
   "metadata": {},
   "source": [
    "### Going Up\n",
    "\n",
    "Continuing the \"family tree\" anology, every tag and every string has a parent, the tag that contins it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-corpus",
   "metadata": {},
   "source": [
    "### .parent\n",
    "You can access an element's parent with the .parent attribute. In the example \"three sister\" document, the <head> tag is the parent of the <title> tag:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ranging-injury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag = soup.title\n",
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "unusual-warning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>The Dormouse's story</title></head>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "competent-toner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.string.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-controversy",
   "metadata": {},
   "source": [
    "The parent of the top level tag like `<html>` is the BeautifulSoup object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "colonial-ministry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_tag = soup.html\n",
    "type(html_tag.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "worse-youth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(soup.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-makeup",
   "metadata": {},
   "source": [
    "### .parents\n",
    "\n",
    "You can iterate over all of an element’s parents with .parents. This example uses .parents to travel from an` <a> `tag buried deep within the document, to the very top of the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "light-western",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = soup.a\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cordless-recommendation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "for parent in link.parents:\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-costume",
   "metadata": {},
   "source": [
    "### Going sideways¶\n",
    "Consider a simple document like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "charitable-ministry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a>\n",
      " <b>\n",
      "  text1\n",
      " </b>\n",
      " <c>\n",
      "  text2\n",
      " </c>\n",
      "</a>\n"
     ]
    }
   ],
   "source": [
    "sibling_soup = BeautifulSoup(\"<a><b>text1</b><c>text2</c></b></a>\", 'html.parser')\n",
    "print(sibling_soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-caribbean",
   "metadata": {},
   "source": [
    "The `<b>` tag and the `<c>` tag are at the same level: they’re both direct children of the same tag. We call them siblings. When a document is `pretty-printed,` siblings show up at the same indentation level. You can also use this relationship in the code you write."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-grass",
   "metadata": {},
   "source": [
    "### .next_siblings and .previous_siblings\n",
    "\n",
    "You can iterate over a tag’s siblings with .next_siblings or `.previous_siblings`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "heated-conservative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.a.next_siblings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "alternate-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "',\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "' and\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "';\\nand they lived at the bottom of a well.'\n"
     ]
    }
   ],
   "source": [
    "for sibling in soup.a.next_siblings:\n",
    "    print(repr(sibling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "boolean-surname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' and\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "',\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "'Once upon a time there were three little sisters; and their names were\\n'\n"
     ]
    }
   ],
   "source": [
    "for sibling in soup.find(id=\"link3\").previous_siblings:\n",
    "    print(repr(sibling))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-shock",
   "metadata": {},
   "source": [
    "### Going back and forth\n",
    "Take a look at the beginning of the “three sisters” document:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-essence",
   "metadata": {},
   "source": [
    "if you want to know more about this please visit this\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-repository",
   "metadata": {},
   "source": [
    "### Children, Parents, and Siblings\n",
    "\n",
    "As stated above the <code>Tag</code> object is a tree of objects we can access the child of the tag or navigate down the branch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "usual-bible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Page Title</title>\n",
       "</head>\n",
       "<body>\n",
       "<h3><b id='boldest'>Lebron James</b></h3>\n",
       "<p> Salary: $ 92,000,000 </p>\n",
       "<h3> Stephen Curry</h3>\n",
       "<p> Salary: $85,000, 000 </p>\n",
       "<h3> Kevin Durant </h3>\n",
       "<p> Salary: $73,200, 000</p>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>Page Title</title>\n",
    "</head>\n",
    "<body>\n",
    "<h3><b id='boldest'>Lebron James</b></h3>\n",
    "<p> Salary: $ 92,000,000 </p>\n",
    "<h3> Stephen Curry</h3>\n",
    "<p> Salary: $85,000, 000 </p>\n",
    "<h3> Kevin Durant </h3>\n",
    "<p> Salary: $73,200, 000</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "loaded-colombia",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'html' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8d181023a4be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'html' is not defined"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html,'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "acceptable-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag object: <title> Page Title</title>\n"
     ]
    }
   ],
   "source": [
    "tag_object=soup.title\n",
    "print(\"tag object:\",tag_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "accomplished-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Mansoor Nijatullah</b></h3>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object=soup.h3\n",
    "tag_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-visit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "former-philosophy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b id=\"boldest\">Mansoor Nijatullah</b>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child =tag_object.b\n",
    "tag_child"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-jumping",
   "metadata": {},
   "source": [
    "You can access the parent with the  `parent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bibliographic-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Mansoor Nijatullah</b></h3>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_tag=tag_child.parent\n",
    "parent_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-portal",
   "metadata": {},
   "source": [
    "<code>tag_object</code> parent is the <code>body</code> element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "natural-letter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><h3><b id=\"boldest\">Mansoor Nijatullah</b></h3><p> Salary: $ 92,000,000 </p><h3> Osman Mansoor</h3><p> Salary: $85,000, 000 </p><h3> Zaid Mansoor </h3><p> Salary: $73,200, 000</p></body>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-coordinate",
   "metadata": {},
   "source": [
    "<code>tag_object</code> sibling is the <code>paragraph</code> element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "progressive-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p> Salary: $ 92,000,000 </p>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_1 = tag_object.next_sibling\n",
    "sibling_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-delay",
   "metadata": {},
   "source": [
    "`sibling_2` is the `header` element which is also a sibling of both `sibling_1` and `tag_object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dried-boulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3> Osman Mansoor</h3>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_2=sibling_1.next_sibling\n",
    "sibling_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-reverse",
   "metadata": {},
   "source": [
    "<h3 id=\"first_question\">Exercise: <code>next_sibling</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-award",
   "metadata": {},
   "source": [
    "Using the object <code>sibling\\_2</code> and the method <code>next_sibling</code> to find the salary of Osman Nijatullah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "explicit-austin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Salary: $85,000, 000 ']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_2.next_sibling.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-exclusion",
   "metadata": {},
   "source": [
    "### HTML Attributes\n",
    "If the tag has attributes, the tag <code>id=\"boldest\"</code> has an attribute <code>id</code> whose value is <code>boldest</code>. You can access a tag’s attributes by treating the tag like a dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "anonymous-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boldest'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-marriage",
   "metadata": {},
   "source": [
    "You can access that dictionary directly as <code>attrs</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "atlantic-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'boldest'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-atlantic",
   "metadata": {},
   "source": [
    "<h2 id=\"filter\">Kinds of filters</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-venture",
   "metadata": {},
   "source": [
    "Filters allow you to find complex patterns, the simplest filter is a string. In this section we will pass a string to a different filter method and Beautiful Soup will perform a match against that exact string.  Consider the following HTML of rocket launchs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "joined-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <td id='flight' >Flight No</td>\n",
       "    <td>Launch site</td>\n",
       "    <td>Payload mass</td>\n",
       "   </tr>\n",
       "  <tr> \n",
       "    <td>1</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
       "    <td>300 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>2</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
       "    <td>94 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>3</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n",
       "    <td>80 kg</td>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<table>\n",
    "  <tr>\n",
    "    <td id='flight' >Flight No</td>\n",
    "    <td>Launch site</td>\n",
    "    <td>Payload mass</td>\n",
    "   </tr>\n",
    "  <tr> \n",
    "    <td>1</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
    "    <td>300 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
    "    <td>94 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n",
    "    <td>80 kg</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-blast",
   "metadata": {},
   "source": [
    "We can store it as a string in the variable <code>table</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "silent-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=\"<table><tr><td id='flight'>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td><td>80 kg</td></tr></table>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "particular-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "table_bs = BeautifulSoup(table, 'html5lib')\n",
    "soup = BeautifulSoup(table,'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-dimension",
   "metadata": {},
   "source": [
    "### find_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-washington",
   "metadata": {},
   "source": [
    "The <code>find_all()</code> method looks through a tag’s descendants and retrieves all descendants that match your filters.\n",
    "\n",
    "<p>\n",
    "The Method signature for <code>find_all(name, attrs, recursive, string, limit, **kwargs)<c/ode>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-victory",
   "metadata": {},
   "source": [
    "### Name\n",
    "When we set the <code>name</code> parameter to a tag name, the method will extract all the tags with that name and its children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "insured-description",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n",
       " <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows = table_bs.find_all('tr')\n",
    "table_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-intention",
   "metadata": {},
   "source": [
    "The result is a Python Iterable just like a list, each element is a <code>tag</code> object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "infrared-population",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row =table_rows[0]\n",
    "print(type(table_rows))\n",
    "first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-champagne",
   "metadata": {},
   "source": [
    "we can obtain the child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "reasonable-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td id=\"flight\">Flight No</td>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row.td"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-nomination",
   "metadata": {},
   "source": [
    "If we iterate through the list, each element corresponds to a row in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "centered-skiing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 is <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>\n",
      "row 1 is <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>\n",
      "row 2 is <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>\n",
      "row 3 is <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(table_rows):\n",
    "    print(\"row\",i,\"is\",row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-accreditation",
   "metadata": {},
   "source": [
    "As <code>row</code> is a <code>cell</code> object, we can apply the method <code>find_all</code> to it and extract table cells in the object <code>cells</code> using the tag <code>td</code>, this is all the children with the name <code>td</code>. The result is a list, each element corresponds to a cell and is a <code>Tag</code> object, we can iterate through this list as well. We can extract the content using the <code>string</code>  attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "annoying-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0\n",
      "column 0 cell <td id=\"flight\">Flight No</td>\n",
      "column 1 cell <td>Launch site</td>\n",
      "column 2 cell <td>Payload mass</td>\n",
      "row 1\n",
      "column 0 cell <td>1</td>\n",
      "column 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>\n",
      "column 2 cell <td>300 kg</td>\n",
      "row 2\n",
      "column 0 cell <td>2</td>\n",
      "column 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n",
      "column 2 cell <td>94 kg</td>\n",
      "row 3\n",
      "column 0 cell <td>3</td>\n",
      "column 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>\n",
      "column 2 cell <td>80 kg</td>\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i)\n",
    "    cells=row.find_all('td')\n",
    "    for j,cell in enumerate(cells):\n",
    "        print('column',j,\"cell\",cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-andrews",
   "metadata": {},
   "source": [
    "If we use a list we can match against any item in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ranging-paint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n",
       " <td id=\"flight\">Flight No</td>,\n",
       " <td>Launch site</td>,\n",
       " <td>Payload mass</td>,\n",
       " <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n",
       " <td>1</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>,\n",
       " <td>300 kg</td>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <td>2</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n",
       " <td>94 kg</td>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>,\n",
       " <td>3</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>,\n",
       " <td>80 kg</td>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input = table_bs.find_all(name=['tr','td'])\n",
    "list_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-asset",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "\n",
    "If the argument is not recognized it will be turned into a filter on the tag’s attributes. For example the <code>id</code>  argument, Beautiful Soup will filter against each tag’s <code>id</code> attribute. For example, the first <code>td</code> elements have a value of <code>id</code> of <code>flight</code>, therefore we can filter based on that <code>id</code> value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "internal-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td id=\"flight\">Flight No</td>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(id='flight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-hours",
   "metadata": {},
   "source": [
    "We can find all the elements that have links to the Florida Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aboriginal-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input = table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\n",
    "list_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-range",
   "metadata": {},
   "source": [
    "If we set the  <code>href</code> attribute to True, regardless of what the value is, the code finds all tags with <code>href</code> value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "matched-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(href=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-stone",
   "metadata": {},
   "source": [
    "There are other methods for dealing with attributes and other related methods; Check out the following <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01#css-selectors'>link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-strike",
   "metadata": {},
   "source": [
    "<h3 id=\"exer_type\">Exercise: <code>find_all</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-replication",
   "metadata": {},
   "source": [
    "Using the logic above, find all the elements without <code>href</code> value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comparative-monte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n",
       " <a></a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n",
       " <a> </a>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-longer",
   "metadata": {},
   "source": [
    "or we can use the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "provincial-experiment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<html><head></head><body><table><tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody></table></body></html>,\n",
       " <head></head>,\n",
       " <body><table><tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody></table></body>,\n",
       " <table><tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody></table>,\n",
       " <tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody>,\n",
       " <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n",
       " <td id=\"flight\">Flight No</td>,\n",
       " <td>Launch site</td>,\n",
       " <td>Payload mass</td>,\n",
       " <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n",
       " <td>1</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>,\n",
       " <a></a>,\n",
       " <td>300 kg</td>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <td>2</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n",
       " <td>94 kg</td>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>,\n",
       " <td>3</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>,\n",
       " <a> </a>,\n",
       " <td>80 kg</td>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(href=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-operations",
   "metadata": {},
   "source": [
    "Using the soup object <code>soup</code>, find the element with the <code>id</code> attribute content set to <code>\"boldest\"</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satisfied-antibody",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'html_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-299bd86caf66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml_doc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtable_bs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'boldest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'html_doc' is not defined"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_doc,'html5lib')\n",
    "table_bs.find_all(id='boldest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "turned-hotel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"boldest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-enclosure",
   "metadata": {},
   "source": [
    "### string\n",
    "\n",
    "With string you can search for strings instead of tags, where we find all the elments with Florida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "graduate-latvia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Florida', 'Florida']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(string=\"Florida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-democracy",
   "metadata": {},
   "source": [
    "## find\n",
    "The <code>find_all()</code> method scans the entire document looking for results, it’s if you are looking for one element you can use the <code>find()</code> method to find the first element in the document. Consider the following two table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "superb-national",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Rocket Launch </h3>\n",
       "\n",
       "<p>\n",
       "<table class='rocket'>\n",
       "  <tr>\n",
       "    <td>Flight No</td>\n",
       "    <td>Launch site</td> \n",
       "    <td>Payload mass</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>1</td>\n",
       "    <td>Florida</td>\n",
       "    <td>300 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>2</td>\n",
       "    <td>Texas</td>\n",
       "    <td>94 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>3</td>\n",
       "    <td>Florida </td>\n",
       "    <td>80 kg</td>\n",
       "  </tr>\n",
       "</table>\n",
       "</p>\n",
       "<p>\n",
       "\n",
       "<h3>Pizza Party  </h3>\n",
       "  \n",
       "    \n",
       "<table class='pizza'>\n",
       "  <tr>\n",
       "    <td>Pizza Place</td>\n",
       "    <td>Orders</td> \n",
       "    <td>Slices </td>\n",
       "   </tr>\n",
       "  <tr>\n",
       "    <td>Domino's Pizza</td>\n",
       "    <td>10</td>\n",
       "    <td>100</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Little Caesars</td>\n",
       "    <td>12</td>\n",
       "    <td >144 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Papa John's </td>\n",
       "    <td>15 </td>\n",
       "    <td>165</td>\n",
       "  </tr>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h3>Rocket Launch </h3>\n",
    "\n",
    "<p>\n",
    "<table class='rocket'>\n",
    "  <tr>\n",
    "    <td>Flight No</td>\n",
    "    <td>Launch site</td> \n",
    "    <td>Payload mass</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Florida</td>\n",
    "    <td>300 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>Texas</td>\n",
    "    <td>94 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>Florida </td>\n",
    "    <td>80 kg</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</p>\n",
    "<p>\n",
    "\n",
    "<h3>Pizza Party  </h3>\n",
    "  \n",
    "    \n",
    "<table class='pizza'>\n",
    "  <tr>\n",
    "    <td>Pizza Place</td>\n",
    "    <td>Orders</td> \n",
    "    <td>Slices </td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <td>Domino's Pizza</td>\n",
    "    <td>10</td>\n",
    "    <td>100</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Little Caesars</td>\n",
    "    <td>12</td>\n",
    "    <td >144 </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Papa John's </td>\n",
    "    <td>15 </td>\n",
    "    <td>165</td>\n",
    "  </tr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "animal-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tables=\"<h3>Rocket Launch </h3><p><table class='rocket'><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class='pizza'><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td >144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-given",
   "metadata": {},
   "source": [
    "We create a `BeaufifulSoup` object `two-tables_bs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pressing-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3>Rocket Launch </h3><p><table class=\"rocket\"><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class=\"pizza\"><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td>144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr></table></p>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tow_tables_bs = BeautifulSoup(two_tables,'html.parser')\n",
    "tow_tables_bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-arrangement",
   "metadata": {},
   "source": [
    "We can find the first table using the tag name table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "brutal-honolulu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"rocket\"><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tow_tables_bs.find(\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-fever",
   "metadata": {},
   "source": [
    "We can filter on the class attribute to find the second table, but because class is a keyword in Python, we add an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solid-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"pizza\"><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td>144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr></table>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tow_tables_bs.find(\"table\",class_='pizza')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-cargo",
   "metadata": {},
   "source": [
    "<h2 id=\"DSCW\">Downloading And Scraping The Contents Of A Web Page</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-alias",
   "metadata": {},
   "source": [
    "We Download the contents of the web page:\n",
    "\n",
    "`url=\"http://www.ibm.com\"`\n",
    "\n",
    "We use <code>get</code> to download the contents of the webpage in text format and store in a variable called <code>data</code>:\n",
    "\n",
    "`data = requests.get(url).text` \n",
    "We create the beaufifulSoup object using the BeautifulSoup constractor. \n",
    "\n",
    "`soup = BeautifulSoup(data,\"html5lib\")`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upset-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://www.ibm.com\"\n",
    "data  = requests.get(url).text \n",
    "soup = BeautifulSoup(data,\"html5lib\")  # create a soup object using the variable 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-holder",
   "metadata": {},
   "source": [
    "Let's scrap all links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "varied-taylor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ibm.com/in/en\n",
      "https://www.ibm.com/sitemap/in/en\n",
      "https://www.ibm.com/in-en/services/applications?lnk=inhpv11\n",
      "https://www.ibm.com/in-en/about#2825811\n",
      "https://in.newsroom.ibm.com/2021-05-26-IBMs-response-to-COVID-19?lnk=inhpv11\n",
      "/in-en/security/zero-trust\n",
      "/in-en/events/cloud-podcasts\n",
      "https://developer.ibm.com/callforcode/?utm_medium=OSocial&utm_source=Blog&utm_content=000031SE&utm_term=10008401&utm_id=Homepage-inside\n",
      "https://www.ibm.com/blogs/journey-to-ai/2021/03/ibm-is-named-a-leader-2021-magic-quadrant-for-data-science-and-machine-learning-platforms/\n",
      "/in-en/products/offers-and-discounts\n",
      "/in-en/cloud/free\n",
      "/in-en/products/cloud-pak-for-data\n",
      "/in-en/security/identity-access-management/cloud-identity\n",
      "https://www.ibm.com/account/reg/signup?formid=urx-46597&lnk=STW_IN_HP_T2_BLK&psrc=NONE&pexp=DEF&lnk2=trial_RoboticProcess\n",
      "/products/digital-learning-subscription/pricing?lnk=STW_IN_HP_T5_BLK&psrc=NONE&pexp=DEF&lnk2=trial_training\n",
      "/in-en/cloud/aspera\n",
      "https://developer.ibm.com/depmodels/cloud/?lnk=hpv18ct16\n",
      "https://developer.ibm.com/technologies/artificial-intelligence?lnk=hpv18ct19\n",
      "https://www.ibm.com/demos/?lnk=hpv18ct12\n",
      "https://developer.ibm.com/?lnk=hpv18ct9\n",
      "https://www.ibm.com/docs/en?lnk=hpv18ct14\n",
      "https://www.redbooks.ibm.com/?lnk=ushpv18ct10\n",
      "https://www.ibm.com/support/home/?lnk=hpv18ct11\n",
      "https://www.ibm.com/training/?lnk=hpv18ct15\n",
      "/in-en/cloud/hybrid?lnk=inhpv18pt1\n",
      "/cloud/learn/public-cloud?lnk=inhpv18pt2\n",
      "/in-en/watson?lnk=inhpv18pt3\n",
      "/in-en/garage?lnk=inhpv18pt4\n",
      "/in-en/blockchain?lnk=inhpv18pt5\n",
      "https://www.ibm.com/thought-leadership/institute-business-value/?lnk=inhpv18pt6\n",
      "/in-en/analytics?lnk=inhpv18pt7\n",
      "/in-en/security?lnk=inhpv18pt8\n",
      "/in-en/financing?lnk=inhpv18pt9\n",
      "/in-en/cloud/redhat?lnk=hpv18ct1\n",
      "/in-en/cloud/automation?lnk=hpv18ct2\n",
      "/in-en/cloud/satellite?lnk=hpv18ct3\n",
      "/in-en/security/zero-trust?lnk=hpv18ct41\n",
      "/in-en/it-infrastructure?lnk=hpv18ct4\n",
      "https://www.ibm.com/quantum-computing?lnk=hpv18ct5\n",
      "/in-en/cloud/learn/kubernetes?lnk=ushpv18ct8?lnk=hpv18ct6\n",
      "/in-en/products/spss-statistics?lnk=ushpv18ct7\n",
      "/in-en/blockchain?lnk=hpv18ct8\n",
      "https://www.ibm.com/in-en/employment?lnk=hpv18ct2\n",
      "https://www.ibm.com/case-studies/federal-bank/?lnk=hpv18cs1\n",
      "/case-studies/search?lnk=hpv18cs2\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a',href=True): # in html cochor/link is represented by the tag <a>\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-block",
   "metadata": {},
   "source": [
    "Scrape all image Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "inappropriate-prospect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"A woman wearing mask while working\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-05-26/Small-rbf07708.jpg\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-05-26/Small-rbf07708.jpg\n",
      "\n",
      "<img alt=\"finger touching digital lock\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-07-12/Small-finger-padlock-orbit%20%281%29.jpg\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-07-12/Small-finger-padlock-orbit%20%281%29.jpg\n",
      "\n",
      "<img alt=\"a mic for recording\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-03-26/Logo-Lockup-444-w-x-320h-px.jpg\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-03-26/Logo-Lockup-444-w-x-320h-px.jpg\n",
      "\n",
      "<img alt=\"a green field\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-05-02/Original-CFC-444x320%20%281%29.jpg\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-05-02/Original-CFC-444x320%20%281%29.jpg\n",
      "\n",
      "<img alt=\"A leader climbing stairs\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-03-26/cc%20%281%29.jpg\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-03-26/cc%20%281%29.jpg\n",
      "\n",
      "<img alt=\"screenshot of the IBM Cloud dashboard\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-04-07/ibm-cloud-trial.png\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-04-07/ibm-cloud-trial.png\n",
      "\n",
      "<img alt=\"Cloud pak for data screenshot\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-04-07/cloud-pak-for-data-trial.png\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-04-07/cloud-pak-for-data-trial.png\n",
      "\n",
      "<img alt=\"screenshot of security-verify-trial\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-04-27/security-verify-trial%20%281%29.png\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-04-27/security-verify-trial%20%281%29.png\n",
      "\n",
      "<img alt=\"Screenshot of IBM RPA\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-04-09/robotic-process-automation.png\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-04-09/robotic-process-automation.png\n",
      "\n",
      "<img alt=\"Screenshot of learning subscription\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-04-30/Digital-Learning-Subscription-trial.png\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-04-30/Digital-Learning-Subscription-trial.png\n",
      "\n",
      "<img alt=\"screenshot of IBM aspera\" class=\"\" loading=\"lazy\" src=\"//1.cms.s81c.com/sites/default/files/2021-04-27/Aspera-on-Cloud-19783-700x420.png\"/>\n",
      "//1.cms.s81c.com/sites/default/files/2021-04-27/Aspera-on-Cloud-19783-700x420.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('img'): \n",
    "    print(link)\n",
    "    print(link.get('src'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-origin",
   "metadata": {},
   "source": [
    "## Scrap data from HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "careful-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below url contains an html table with data about colors and color codes.\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-cameroon",
   "metadata": {},
   "source": [
    "Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check how many rows and columns are there in the color table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "amino-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "european-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-waterproof",
   "metadata": {},
   "source": [
    "Find all the table in the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ignored-scanning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = soup.find('table')\n",
    "type(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "technological-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name ---->None\n",
      "lightsalmon ---->#FFA07A\n",
      "salmon ---->#FA8072\n",
      "darksalmon ---->#E9967A\n",
      "lightcoral ---->#F08080\n",
      "coral ---->#FF7F50\n",
      "tomato ---->#FF6347\n",
      "orangered ---->#FF4500\n",
      "gold ---->#FFD700\n",
      "orange ---->#FFA500\n",
      "darkorange ---->#FF8C00\n",
      "lightyellow ---->#FFFFE0\n",
      "lemonchiffon ---->#FFFACD\n",
      "papayawhip ---->#FFEFD5\n",
      "moccasin ---->#FFE4B5\n",
      "peachpuff ---->#FFDAB9\n",
      "palegoldenrod ---->#EEE8AA\n",
      "khaki ---->#F0E68C\n",
      "darkkhaki ---->#BDB76B\n",
      "yellow ---->#FFFF00\n",
      "lawngreen ---->#7CFC00\n",
      "chartreuse ---->#7FFF00\n",
      "limegreen ---->#32CD32\n",
      "lime ---->#00FF00\n",
      "forestgreen ---->#228B22\n",
      "green ---->#008000\n",
      "powderblue ---->#B0E0E6\n",
      "lightblue ---->#ADD8E6\n",
      "lightskyblue ---->#87CEFA\n",
      "skyblue ---->#87CEEB\n",
      "deepskyblue ---->#00BFFF\n",
      "lightsteelblue ---->#B0C4DE\n",
      "dodgerblue ---->#1E90FF\n"
     ]
    }
   ],
   "source": [
    "#Get all rows from the table\n",
    "for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n",
    "    # get all the column for each row.\n",
    "    cols = row.find_all('td') # in html a column is represented by the tag <td>\n",
    "    color_name = cols[2].string  # store the value in column 3 as color_name\n",
    "    color_code = cols[3].string # store the value in column 4 as color_code\n",
    "    print(\"{} ---->{}\".format(color_name,color_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-transition",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using BeautifulSoup and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rotary-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adjacent-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below url contains html tables with data about world population.\n",
    "url = \"https://en.wikipedia.org/wiki/World_population\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-complement",
   "metadata": {},
   "source": [
    "Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check the tables on the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "therapeutic-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "creative-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "prescription-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all html tables in the web page.\n",
    "tables = soup.find_all('table')  # in html table is represented by the tag <table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "prostate-banner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see how many tables were found by checking the length of the tables list\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-picture",
   "metadata": {},
   "source": [
    "Assume that we are looking for the `10 most densly populated countries` table, we can look through the tables list and find the right one we are look for based on the data in each table or we can search for the table name if it is in the table but this option might not always work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "structural-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "for index,table in enumerate(tables):\n",
    "    if (\"10 most densely populated countries\" in str(table)):\n",
    "        table_index = index\n",
    "print(table_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-trinidad",
   "metadata": {},
   "source": [
    "See if you can locate the table name of the table, `10 most densly populated countries`, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "criminal-greensboro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"wikitable sortable\" style=\"text-align:right\">\n",
      " <caption>\n",
      "  10 most densely populated countries\n",
      "  <small>\n",
      "   (with population above 5 million)\n",
      "  </small>\n",
      " </caption>\n",
      " <tbody>\n",
      "  <tr>\n",
      "   <th>\n",
      "    Rank\n",
      "   </th>\n",
      "   <th>\n",
      "    Country\n",
      "   </th>\n",
      "   <th>\n",
      "    Population\n",
      "   </th>\n",
      "   <th>\n",
      "    Area\n",
      "    <br/>\n",
      "    <small>\n",
      "     (km\n",
      "     <sup>\n",
      "      2\n",
      "     </sup>\n",
      "     )\n",
      "    </small>\n",
      "   </th>\n",
      "   <th>\n",
      "    Density\n",
      "    <br/>\n",
      "    <small>\n",
      "     (pop/km\n",
      "     <sup>\n",
      "      2\n",
      "     </sup>\n",
      "     )\n",
      "    </small>\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    1\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"3456\" data-file-width=\"5184\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/23px-Flag_of_Singapore.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/35px-Flag_of_Singapore.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/45px-Flag_of_Singapore.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Singapore\" title=\"Singapore\">\n",
      "     Singapore\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    5,704,000\n",
      "   </td>\n",
      "   <td>\n",
      "    710\n",
      "   </td>\n",
      "   <td>\n",
      "    8,033\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    2\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"1000\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/23px-Flag_of_Bangladesh.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/35px-Flag_of_Bangladesh.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/46px-Flag_of_Bangladesh.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Bangladesh\" title=\"Bangladesh\">\n",
      "     Bangladesh\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    171,040,000\n",
      "   </td>\n",
      "   <td>\n",
      "    143,998\n",
      "   </td>\n",
      "   <td>\n",
      "    1,188\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    3\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/23px-Flag_of_Lebanon.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/35px-Flag_of_Lebanon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/45px-Flag_of_Lebanon.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Lebanon\" title=\"Lebanon\">\n",
      "     Lebanon\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    6,856,000\n",
      "   </td>\n",
      "   <td>\n",
      "    10,452\n",
      "   </td>\n",
      "   <td>\n",
      "    656\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    4\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/23px-Flag_of_the_Republic_of_China.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/35px-Flag_of_the_Republic_of_China.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/45px-Flag_of_the_Republic_of_China.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Taiwan\" title=\"Taiwan\">\n",
      "     Taiwan\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    23,604,000\n",
      "   </td>\n",
      "   <td>\n",
      "    36,193\n",
      "   </td>\n",
      "   <td>\n",
      "    652\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    5\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/23px-Flag_of_South_Korea.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/35px-Flag_of_South_Korea.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/45px-Flag_of_South_Korea.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/South_Korea\" title=\"South Korea\">\n",
      "     South Korea\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    51,781,000\n",
      "   </td>\n",
      "   <td>\n",
      "    99,538\n",
      "   </td>\n",
      "   <td>\n",
      "    520\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    6\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"720\" data-file-width=\"1080\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/23px-Flag_of_Rwanda.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/35px-Flag_of_Rwanda.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/45px-Flag_of_Rwanda.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Rwanda\" title=\"Rwanda\">\n",
      "     Rwanda\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    12,374,000\n",
      "   </td>\n",
      "   <td>\n",
      "    26,338\n",
      "   </td>\n",
      "   <td>\n",
      "    470\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    7\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"1000\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/56/Flag_of_Haiti.svg/23px-Flag_of_Haiti.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/56/Flag_of_Haiti.svg/35px-Flag_of_Haiti.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/56/Flag_of_Haiti.svg/46px-Flag_of_Haiti.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Haiti\" title=\"Haiti\">\n",
      "     Haiti\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    11,578,000\n",
      "   </td>\n",
      "   <td>\n",
      "    27,065\n",
      "   </td>\n",
      "   <td>\n",
      "    428\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    8\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/23px-Flag_of_the_Netherlands.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/35px-Flag_of_the_Netherlands.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/45px-Flag_of_the_Netherlands.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Netherlands\" title=\"Netherlands\">\n",
      "     Netherlands\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    17,620,000\n",
      "   </td>\n",
      "   <td>\n",
      "    41,526\n",
      "   </td>\n",
      "   <td>\n",
      "    424\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    9\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"800\" data-file-width=\"1100\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Flag_of_Israel.svg/21px-Flag_of_Israel.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Flag_of_Israel.svg/32px-Flag_of_Israel.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Flag_of_Israel.svg/41px-Flag_of_Israel.svg.png 2x\" width=\"21\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Israel\" title=\"Israel\">\n",
      "     Israel\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    9,370,000\n",
      "   </td>\n",
      "   <td>\n",
      "    22,072\n",
      "   </td>\n",
      "   <td>\n",
      "    425\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    10\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon\">\n",
      "     <img alt=\"\" class=\"thumbborder\" data-file-height=\"900\" data-file-width=\"1350\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/23px-Flag_of_India.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/35px-Flag_of_India.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/45px-Flag_of_India.svg.png 2x\" width=\"23\"/>\n",
      "    </span>\n",
      "    <a href=\"/wiki/India\" title=\"India\">\n",
      "     India\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    1,379,660,000\n",
      "   </td>\n",
      "   <td>\n",
      "    3,287,240\n",
      "   </td>\n",
      "   <td>\n",
      "    420\n",
      "   </td>\n",
      "  </tr>\n",
      " </tbody>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tables[table_index].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "sweet-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = pd.DataFrame(columns=[\"Rank\", \"Country\", \"Population\", \"Area\", \"Density\"])\n",
    "\n",
    "for row in tables[table_index].tbody.find_all(\"tr\"):\n",
    "    col = row.find_all(\"td\")\n",
    "    if (col != []):\n",
    "        rank = col[0].text\n",
    "        country = col[1].text\n",
    "        population = col[2].text.strip()\n",
    "        area = col[3].text.strip()\n",
    "        density = col[4].text.strip()\n",
    "        population_data = population_data.append({\"Rank\":rank, \"Country\":country, \"Population\":population, \"Area\":area, \"Density\":density}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "raised-requirement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area</th>\n",
       "      <th>Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5,704,000</td>\n",
       "      <td>710</td>\n",
       "      <td>8,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>171,040,000</td>\n",
       "      <td>143,998</td>\n",
       "      <td>1,188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>6,856,000</td>\n",
       "      <td>10,452</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>23,604,000</td>\n",
       "      <td>36,193</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51,781,000</td>\n",
       "      <td>99,538</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>12,374,000</td>\n",
       "      <td>26,338</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>11,578,000</td>\n",
       "      <td>27,065</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17,620,000</td>\n",
       "      <td>41,526</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9,370,000</td>\n",
       "      <td>22,072</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1,379,660,000</td>\n",
       "      <td>3,287,240</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank       Country     Population       Area Density\n",
       "0    1     Singapore      5,704,000        710   8,033\n",
       "1    2    Bangladesh    171,040,000    143,998   1,188\n",
       "2    3       Lebanon      6,856,000     10,452     656\n",
       "3    4        Taiwan     23,604,000     36,193     652\n",
       "4    5   South Korea     51,781,000     99,538     520\n",
       "5    6        Rwanda     12,374,000     26,338     470\n",
       "6    7         Haiti     11,578,000     27,065     428\n",
       "7    8   Netherlands     17,620,000     41,526     424\n",
       "8    9        Israel      9,370,000     22,072     425\n",
       "9   10         India  1,379,660,000  3,287,240     420"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-essex",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using BeautifulSoup and read_html\n",
    "\n",
    "Using the same `url`, `data`, `soup`, and `tables` object as in the last section we can use the `read_html` function to create a DataFrame.\n",
    "\n",
    "Remember the table we need is located in `tables[table_index]`\n",
    "\n",
    "We can now use the `pandas` function `read_html` and give it the string version of the table as well as the `flavor` which is the parsing engine `bs4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "successful-railway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area(km2)</th>\n",
       "      <th>Density(pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5704000</td>\n",
       "      <td>710</td>\n",
       "      <td>8033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>171040000</td>\n",
       "      <td>143998</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>6856000</td>\n",
       "      <td>10452</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>23604000</td>\n",
       "      <td>36193</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51781000</td>\n",
       "      <td>99538</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>12374000</td>\n",
       "      <td>26338</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>11578000</td>\n",
       "      <td>27065</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17620000</td>\n",
       "      <td>41526</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9370000</td>\n",
       "      <td>22072</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1379660000</td>\n",
       "      <td>3287240</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n",
       "0     1    Singapore     5704000        710              8033\n",
       "1     2   Bangladesh   171040000     143998              1188\n",
       "2     3      Lebanon     6856000      10452               656\n",
       "3     4       Taiwan    23604000      36193               652\n",
       "4     5  South Korea    51781000      99538               520\n",
       "5     6       Rwanda    12374000      26338               470\n",
       "6     7        Haiti    11578000      27065               428\n",
       "7     8  Netherlands    17620000      41526               424\n",
       "8     9       Israel     9370000      22072               425\n",
       "9    10        India  1379660000    3287240               420"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_html(str(tables[5]), flavor='bs4')\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-number",
   "metadata": {},
   "source": [
    "The function `read_html` always returns a list of DataFrames so we must pick the one we want out of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "increased-merchandise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area(km2)</th>\n",
       "      <th>Density(pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5704000</td>\n",
       "      <td>710</td>\n",
       "      <td>8033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>171040000</td>\n",
       "      <td>143998</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>6856000</td>\n",
       "      <td>10452</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>23604000</td>\n",
       "      <td>36193</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51781000</td>\n",
       "      <td>99538</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>12374000</td>\n",
       "      <td>26338</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>11578000</td>\n",
       "      <td>27065</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17620000</td>\n",
       "      <td>41526</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9370000</td>\n",
       "      <td>22072</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1379660000</td>\n",
       "      <td>3287240</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n",
       "0     1    Singapore     5704000        710              8033\n",
       "1     2   Bangladesh   171040000     143998              1188\n",
       "2     3      Lebanon     6856000      10452               656\n",
       "3     4       Taiwan    23604000      36193               652\n",
       "4     5  South Korea    51781000      99538               520\n",
       "5     6       Rwanda    12374000      26338               470\n",
       "6     7        Haiti    11578000      27065               428\n",
       "7     8  Netherlands    17620000      41526               424\n",
       "8     9       Israel     9370000      22072               425\n",
       "9    10        India  1379660000    3287240               420"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_data_read_html = pd.read_html(str(tables[5]),flavor='bs4')[0]\n",
    "population_data_read_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-alert",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using read_html\n",
    "\n",
    "We can also use the `read_html` function to directly get DataFrames from a `url`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "infinite-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list = pd.read_html(url,flavor='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-front",
   "metadata": {},
   "source": [
    "We can see there are 25 DataFrames just like when we used `find_all` on the `soup` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "operational-store",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-mumbai",
   "metadata": {},
   "source": [
    "We can also use the `match` parameter to select the specific table we want. If the table contains a string matching the text it will be read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "numerous-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area(km2)</th>\n",
       "      <th>Density(pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5704000</td>\n",
       "      <td>710</td>\n",
       "      <td>8033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>171040000</td>\n",
       "      <td>143998</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>6856000</td>\n",
       "      <td>10452</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>23604000</td>\n",
       "      <td>36193</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51781000</td>\n",
       "      <td>99538</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>12374000</td>\n",
       "      <td>26338</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>11578000</td>\n",
       "      <td>27065</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17620000</td>\n",
       "      <td>41526</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9370000</td>\n",
       "      <td>22072</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1379660000</td>\n",
       "      <td>3287240</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n",
       "0     1    Singapore     5704000        710              8033\n",
       "1     2   Bangladesh   171040000     143998              1188\n",
       "2     3      Lebanon     6856000      10452               656\n",
       "3     4       Taiwan    23604000      36193               652\n",
       "4     5  South Korea    51781000      99538               520\n",
       "5     6       Rwanda    12374000      26338               470\n",
       "6     7        Haiti    11578000      27065               428\n",
       "7     8  Netherlands    17620000      41526               424\n",
       "8     9       Israel     9370000      22072               425\n",
       "9    10        India  1379660000    3287240               420"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(url,match=\"10 most densely populated countries\",flavor='bs4')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-width",
   "metadata": {},
   "source": [
    "## Let's do a small project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-prayer",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-shadow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-paste",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-assets",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
